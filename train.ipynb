{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37264bitanaconda3virtualenv0da93e78e7984fa8816047766ea5d289",
   "display_name": "Python 3.7.2 64-bit ('anaconda3': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from UCI dataset repo\n",
    "data = np.loadtxt('https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt', delimiter=',')\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column names\n",
    "clean_columns = ['variance_of_wavelet', 'skewness_of_wavelet',\n",
    "                 'curtosis_of_wavelet', 'entropy_of_wavelet',\n",
    "                 'class']\n",
    "\n",
    "data.columns = clean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variance_of_wavelet</th>\n      <th>skewness_of_wavelet</th>\n      <th>curtosis_of_wavelet</th>\n      <th>entropy_of_wavelet</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>3.62160</td>\n      <td>8.6661</td>\n      <td>-2.8073</td>\n      <td>-0.44699</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>4.54590</td>\n      <td>8.1674</td>\n      <td>-2.4586</td>\n      <td>-1.46210</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.86600</td>\n      <td>-2.6383</td>\n      <td>1.9242</td>\n      <td>0.10645</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.45660</td>\n      <td>9.5228</td>\n      <td>-4.0112</td>\n      <td>-3.59440</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.32924</td>\n      <td>-4.4552</td>\n      <td>4.5718</td>\n      <td>-0.98880</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   variance_of_wavelet  skewness_of_wavelet  curtosis_of_wavelet  \\\n0              3.62160               8.6661              -2.8073   \n1              4.54590               8.1674              -2.4586   \n2              3.86600              -2.6383               1.9242   \n3              3.45660               9.5228              -4.0112   \n4              0.32924              -4.4552               4.5718   \n\n   entropy_of_wavelet  class  \n0            -0.44699    0.0  \n1            -1.46210    0.0  \n2             0.10645    0.0  \n3            -3.59440    0.0  \n4            -0.98880    0.0  "
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check column names\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target and features as separate dataframes for sklearn APIs\n",
    "X = data.drop('class', axis=1)\n",
    "y = data[['class']].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified sampling based on the distribution of the target vector, y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n"
    }
   ],
   "source": [
    "# Network Architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(50,activation='relu',input_shape=(X.shape[1],)))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 1097 samples, validate on 275 samples\nEpoch 1/20\n1097/1097 [==============================] - 1s 559us/sample - loss: 0.6246 - acc: 0.7758 - val_loss: 0.5294 - val_acc: 0.9018\nEpoch 2/20\n1097/1097 [==============================] - 0s 74us/sample - loss: 0.4215 - acc: 0.9325 - val_loss: 0.3276 - val_acc: 0.9200\nEpoch 3/20\n1097/1097 [==============================] - 0s 73us/sample - loss: 0.2408 - acc: 0.9535 - val_loss: 0.1812 - val_acc: 0.9527\nEpoch 4/20\n1097/1097 [==============================] - 0s 74us/sample - loss: 0.1339 - acc: 0.9681 - val_loss: 0.1098 - val_acc: 0.9673\nEpoch 5/20\n1097/1097 [==============================] - 0s 77us/sample - loss: 0.0855 - acc: 0.9781 - val_loss: 0.0742 - val_acc: 0.9782\nEpoch 6/20\n1097/1097 [==============================] - 0s 69us/sample - loss: 0.0622 - acc: 0.9809 - val_loss: 0.0578 - val_acc: 0.9782\nEpoch 7/20\n1097/1097 [==============================] - 0s 71us/sample - loss: 0.0495 - acc: 0.9827 - val_loss: 0.0456 - val_acc: 0.9782\nEpoch 8/20\n1097/1097 [==============================] - 0s 72us/sample - loss: 0.0403 - acc: 0.9827 - val_loss: 0.0375 - val_acc: 0.9818\nEpoch 9/20\n1097/1097 [==============================] - 0s 70us/sample - loss: 0.0330 - acc: 0.9900 - val_loss: 0.0316 - val_acc: 0.9891\nEpoch 10/20\n1097/1097 [==============================] - 0s 78us/sample - loss: 0.0273 - acc: 0.9900 - val_loss: 0.0272 - val_acc: 0.9891\nEpoch 11/20\n1097/1097 [==============================] - 0s 77us/sample - loss: 0.0229 - acc: 0.9936 - val_loss: 0.0230 - val_acc: 0.9964\nEpoch 12/20\n1097/1097 [==============================] - 0s 81us/sample - loss: 0.0197 - acc: 0.9964 - val_loss: 0.0199 - val_acc: 1.0000\nEpoch 13/20\n1097/1097 [==============================] - 0s 76us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\nEpoch 14/20\n1097/1097 [==============================] - 0s 74us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\nEpoch 15/20\n1097/1097 [==============================] - 0s 70us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\nEpoch 16/20\n1097/1097 [==============================] - 0s 69us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\nEpoch 17/20\n1097/1097 [==============================] - 0s 81us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\nEpoch 18/20\n1097/1097 [==============================] - 0s 72us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\nEpoch 19/20\n1097/1097 [==============================] - 0s 70us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\nEpoch 20/20\n1097/1097 [==============================] - 0s 71us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1a3d909f98>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and validate generated model with the unseen test set\n",
    "model.fit(X_train, y_train.values, epochs=20, validation_data=(X_test, y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['scaler.joblib']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model objects - predictor and scaler object\n",
    "model.save('banknote_authentication_model.h5')\n",
    "joblib.dump(sc, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}